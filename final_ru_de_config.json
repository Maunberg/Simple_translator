{
  "timestamp": "2025-10-01T20:01:12.166425",
  "config": {
    "way_to_data": "/mnt/asr_hot/dutov/study/ml/lab_1_nlp/tatoeba_pairs_filtered.csv",
    "langs": [
      "eng",
      "epo",
      "fra",
      "deu",
      "rus",
      "spa",
      "tur",
      "ita",
      "jpn",
      "por"
    ],
    "language_selection": [
      "rus",
      "deu"
    ],
    "way_to_vocab": "vocab.json",
    "way_to_tokenized": "tokenized_data.pkl",
    "way_to_model": "transformer_model_rus_deu.pth",
    "way_to_config": "model_config_rus_deu.json",
    "d_model": 128,
    "num_heads": 4,
    "num_layers": 3,
    "d_ff": 1024,
    "max_seq_length": 128,
    "dropout": 0.1,
    "device": "cuda",
    "batch_size": 64,
    "learning_rate": 0.001,
    "num_epochs_pretrain": 40,
    "num_epochs_finetune": 20,
    "save_every": 5,
    "eval_every": 1,
    "lang_tokens": {
      "eng": "<EN>",
      "rus": "<RU>",
      "fra": "<FR>",
      "deu": "<DE>",
      "spa": "<ES>",
      "ita": "<IT>",
      "por": "<PT>",
      "tur": "<TR>",
      "jpn": "<JP>",
      "epo": "<EO>"
    }
  },
  "pretrain_losses": [
    4.213518375200901,
    3.0660005552780363,
    2.697899445639198,
    2.506627640898132,
    2.3847517074163176,
    2.294824620752955,
    2.225038451465192,
    2.170358704597083,
    2.1258605483691015,
    2.086352316093158,
    2.0532075266230145,
    2.022988684153189,
    1.9950289252827427,
    1.9712181918914267,
    1.9456187908969547,
    1.9227776836748185,
    1.9043731738768739,
    1.8862945738480745,
    1.8719674041729397,
    1.856478974486527,
    1.8447969753341416,
    1.832119329345993,
    1.8200648247455915,
    1.8081693262836904,
    1.7950902364898687,
    1.7830780257673002,
    1.7726261661482199,
    1.7626907906616573,
    1.7515875843513635,
    1.7435014699804643,
    1.7336677984439954,
    1.7248147238506863,
    1.7147877110534702,
    1.7085685962660504,
    1.7001061189797821,
    1.6909355808801785,
    1.6846898606999021,
    1.6767552321949772,
    1.6719005485816574,
    1.6645331673265265
  ],
  "finetune_losses": [
    1.418254166718218,
    1.3486987332420808,
    1.3294431419245234,
    1.3204151756021931,
    1.3138081259680852,
    1.3094820821585624,
    1.3063889573552008,
    1.303877028028245,
    1.302445553352439,
    1.299281800071204,
    1.297977327471077,
    1.2970316036611,
    1.2958742730731398,
    1.2924375636947922,
    1.2928121974926419,
    1.2894539721660392,
    1.2895634149913278,
    1.2897990483814454,
    1.2868343685165569,
    1.2857475007508383
  ],
  "final_pretrain_loss": 1.6645331673265265,
  "final_finetune_loss": 1.2857475007508383
}